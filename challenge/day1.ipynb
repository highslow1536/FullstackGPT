{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjhs\\AppData\\Local\\Temp\\ipykernel_9428\\4097912837.py:3: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjhs\\AppData\\Local\\Temp\\ipykernel_9428\\1071410660.py:1: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  model.predict('hello?')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('hello?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "writing_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert in writing haikus about programming languages.\"),\n",
    "    (\"user\", \"Please write a haiku about {language}.\")\n",
    "])\n",
    "explaining_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert in explaining haikus.\"),\n",
    "    (\"user\", \"Please explain the following haiku in detail:\\n\\n{haiku}\")\n",
    "])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "# writing_chain = LLMChain(llm=model, prompt=writing_prompt)\n",
    "# explaining_chain = LLMChain(llm=model, prompt=explaining_prompt)\n",
    "\n",
    "writing_chain = writing_prompt | model\n",
    "explaining_chain = explaining_prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='This haiku reflects on the elegance and simplicity of Python programming language, particularly focusing on its neat syntax and the legacy of Guido van Rossum, the creator of Python. \\n\\nThe first line, \"Indentation rules,\" highlights one of the distinctive features of Python which is its use of indentation to define code blocks. This unique aspect of the language is often praised for enforcing clean and readable code.\\n\\nThe second line, \"Python\\'s syntax is so clean,\" emphasizes the overall clarity and simplicity of Python\\'s syntax. Python is known for its readability and ease of use, making it a popular choice for beginners and experienced programmers alike.\\n\\nThe final line, \"Guido\\'s legacy,\" pays tribute to Guido van Rossum, the Dutch programmer who created Python in the late 1980s. Guido\\'s vision and contributions to the programming community have left a lasting impact, shaping the way Python is used and regarded in the world of software development.\\n\\nOverall, this haiku celebrates the beauty and influence of Python as a programming language, as well as the enduring legacy of its creator, Guido van Rossum.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 198, 'total_tokens': 421, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-86d3e5d7-1cb5-4bf4-b365-1735a89d188a-0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_chain = {\"haiku\": writing_chain} | explaining_chain\n",
    "\n",
    "combined_chain.invoke({\"language\": \"Python\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
